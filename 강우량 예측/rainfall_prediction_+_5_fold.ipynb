{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rainfall prediction + 5 fold.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rIrhXeGvTnn",
        "outputId": "eb505988-b75e-4710-b883-9a447a910145",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "import os\n",
        "\n",
        "root_path = \"/content/drive/My Drive/강우예측AI\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3k2U0KMvvlLh"
      },
      "source": [
        "!cp -r /content/drive/My\\ Drive/강우예측AI ."
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpAQ9cbWvrHF"
      },
      "source": [
        "import zipfile"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0EpW5B4ov8-F",
        "outputId": "bbbb3c1a-d4d5-4895-cf9a-fe854f8530bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "try:\n",
        "    with zipfile.ZipFile(\"강우예측AI/train.zip\") as zf:\n",
        "        zf.extractall()\n",
        "        print(\"uncompress success\")\n",
        "\n",
        "except:\n",
        "  pass"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "uncompress success\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2KOsXAmwDpI",
        "outputId": "ca60eb28-2e97-4046-9d29-b043000a8125",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "try:\n",
        "    with zipfile.ZipFile(\"강우예측AI/test.zip\") as zf:\n",
        "        zf.extractall()\n",
        "        print(\"uncompress success\")\n",
        "\n",
        "except:\n",
        "  pass"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "uncompress success\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-YR0QVUwEOs"
      },
      "source": [
        "!cp 강우예측AI/sample_submission.csv ."
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_K-rZGHPwIQP"
      },
      "source": [
        "import glob\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pylab as plt\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, MaxPooling2D, BatchNormalization, concatenate, Input\n",
        "from tensorflow.keras import Model\n",
        "import imgaug\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "If3q_agGwJ-W"
      },
      "source": [
        "# train data 생성\n",
        "train_files = glob.glob('/content/train/*.npy')\n",
        "len(train_files)\n",
        "train_files = np.array(train_files)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FX17xEFxxsjX",
        "outputId": "6feec973-1774-4275-ab7f-96fc7d0891ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# train 데이터 생성\n",
        "len(train_files)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "62735"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UztxWlHwMGn"
      },
      "source": [
        "def trainGenerator():\n",
        "    for file in tr_file:\n",
        "        dataset = np.load(file)\n",
        "        target= dataset[:,:,-1].reshape(120,120,1)        \n",
        "        remove_minus = np.where(target < 0, 0, target)\n",
        "        feature = dataset[:,:,:4]\n",
        "\n",
        "\n",
        "\n",
        "        yield (feature, remove_minus)\n",
        "\n",
        "def valGenerator():\n",
        "    for file in val_file:\n",
        "        dataset = np.load(file)\n",
        "        target= dataset[:,:,-1].reshape(120,120,1)        \n",
        "        remove_minus = np.where(target < 0, 0, target)\n",
        "        feature = dataset[:,:,:4]\n",
        "\n",
        "\n",
        "        yield (feature, remove_minus)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9s3A0n9wN4E"
      },
      "source": [
        "# 최초 베이스라인\n",
        "def base_model(input_layer, start_neurons):\n",
        "    \n",
        "    conv1 = Conv2D(start_neurons * 1, (3, 3), activation=\"relu\", padding=\"same\")(input_layer)\n",
        "    pool1 = BatchNormalization()(conv1)\n",
        "    pool1 = MaxPooling2D((2, 2))(pool1)\n",
        "\n",
        "    conv2 = Conv2D(start_neurons * 2, (3, 3), activation=\"relu\", padding=\"same\")(pool1)\n",
        "    pool2 = BatchNormalization()(conv2)\n",
        "    pool2 = MaxPooling2D((2, 2))(pool2)\n",
        "\n",
        "    convm = Conv2D(start_neurons * 4, (3, 3), activation=\"relu\", padding=\"same\")(pool2)\n",
        "\n",
        "    deconv2 = Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding=\"same\")(convm)\n",
        "    uconv2 = concatenate([deconv2, conv2])\n",
        "    uconv2 = Conv2D(start_neurons * 2, (3, 3), activation=\"relu\", padding=\"same\")(uconv2)\n",
        "    uconv2 = BatchNormalization()(uconv2)\n",
        "\n",
        "    deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv2)\n",
        "    uconv1 = concatenate([deconv1, conv1])\n",
        "    uconv1 = Conv2D(start_neurons * 1, (3, 3), activation=\"relu\", padding=\"same\")(uconv1)\n",
        "    uconv1 = BatchNormalization()(uconv1)\n",
        "    output_layer = Conv2D(1, (1,1), padding=\"same\", activation='relu')(uconv1)\n",
        "    \n",
        "    return output_layer"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5onCw-NawPeu",
        "outputId": "e0ef0445-e7a5-4932-852b-f143319134cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import gc\n",
        "from sklearn.model_selection import KFold\n",
        "kf = KFold(n_splits=5, random_state=42)\n",
        "for fold, (train, val) in enumerate(kf.split(train_files)):\n",
        "  #print(type(val))\n",
        "  val_file = train_files[val]\n",
        "  tr_file = train_files[train]\n",
        "  \n",
        "\n",
        "  train_dataset = tf.data.Dataset.from_generator(trainGenerator, (tf.float32, tf.float32), (tf.TensorShape([120,120,4]),tf.TensorShape([120,120,1])))\n",
        "  train_dataset = train_dataset.shuffle(256)\n",
        "\n",
        "  train_dataset = train_dataset.batch(128).prefetch(1)\n",
        "\n",
        "  val_dataset = tf.data.Dataset.from_generator(valGenerator, (tf.float32, tf.float32), (tf.TensorShape([120,120,4]),tf.TensorShape([120,120,1])))\n",
        "  val_dataset = val_dataset.batch(128).prefetch(1)\n",
        "\n",
        "  \n",
        "\n",
        "  input_layer = Input((120, 120, 4))\n",
        "  output_layer = base_model(input_layer,64)\n",
        "\n",
        "  model = Model(input_layer, output_layer)\n",
        "  adam = tf.keras.optimizers.Adam()\n",
        "  model.compile(optimizer=adam, loss='mae')\n",
        "\n",
        "\n",
        "  callbacks = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor='val_loss', factor=0.2, patience=2, verbose=0, mode='min',\n",
        "    min_delta=0.0001, cooldown=0, min_lr=0\n",
        "  )\n",
        "\n",
        "  sv = tf.keras.callbacks.ModelCheckpoint(\n",
        "        os.path.join(root_path,f'{fold}-rain.h5'), monitor='val_loss', verbose=0, save_best_only=True,\n",
        "        save_weights_only=True, mode='min', save_freq='epoch')\n",
        "\n",
        "  model.fit(train_dataset, epochs = 1, verbose=1, validation_data=val_dataset, callbacks=[callbacks, sv])\n",
        "\n",
        "  del model\n",
        "  gc.collect()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      2/Unknown - 0s 160ms/step - loss: 11.5687WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1135s vs `on_train_batch_end` time: 0.2056s). Check your callbacks.\n",
            "393/393 [==============================] - 154s 393ms/step - loss: 6.0194 - val_loss: 3.5382\n",
            "      2/Unknown - 0s 162ms/step - loss: 13.2906WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1171s vs `on_train_batch_end` time: 0.2065s). Check your callbacks.\n",
            "393/393 [==============================] - 155s 395ms/step - loss: 5.8701 - val_loss: 5.6270\n",
            "      2/Unknown - 0s 159ms/step - loss: 14.5268WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1125s vs `on_train_batch_end` time: 0.2051s). Check your callbacks.\n",
            "393/393 [==============================] - 142s 361ms/step - loss: 5.9309 - val_loss: 3.5728\n",
            "      2/Unknown - 0s 161ms/step - loss: 14.0107WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1161s vs `on_train_batch_end` time: 0.2056s). Check your callbacks.\n",
            "393/393 [==============================] - 139s 354ms/step - loss: 5.8466 - val_loss: 3.9234\n",
            "      2/Unknown - 0s 161ms/step - loss: 14.5330WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1172s vs `on_train_batch_end` time: 0.2055s). Check your callbacks.\n",
            "393/393 [==============================] - 139s 353ms/step - loss: 5.9890 - val_loss: 3.5064\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWRTkg8dwRX2"
      },
      "source": [
        "import gc\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "def loss(final_X_answers, final_X_pred):\n",
        "  pred = final_X_pred\n",
        "  answer = final_X_answers\n",
        "  mae = mean_absolute_error(answer, pred)\n",
        "  print(mae)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOY9xD0MxTii"
      },
      "source": [
        "input_layer = Input((120, 120, 4))\n",
        "output_layer = base_model(input_layer,64)\n",
        "model = Model(input_layer, output_layer)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jb0fvWYQxV7t",
        "outputId": "cd24393d-f728-40d1-bc84-7f09afd1260a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "test_files = sorted(glob.glob('test*.npy'))\n",
        "X_test = []\n",
        "for file in tqdm(test_files, desc = 'test'):\n",
        "    data = np.load(file)\n",
        "    X_test.append(data)\n",
        "\n",
        "X_test = np.array(X_test)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test: 100%|██████████| 2674/2674 [00:04<00:00, 592.99it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0m6BW6LMxXVf",
        "outputId": "2833c970-30ab-48e3-dd54-bf40638c16e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "kf = KFold(n_splits=5, random_state=42)\n",
        "total_val = []\n",
        "total_answer = []\n",
        "test_preds = []\n",
        "\n",
        "for fold, (train, val) in enumerate(kf.split(train_files)):\n",
        "\n",
        "  val_file = train_files[val]\n",
        "\n",
        "  X_val = []\n",
        "  X_answers = []\n",
        "  \n",
        "  for file in tqdm(val_file, desc='val'):\n",
        "    data = np.load(file)\n",
        "    X_answer = data[:,:,-1].reshape(14400)\n",
        "    X_input = data[:,:,:4]\n",
        "  \n",
        "    X_val.append(X_input)\n",
        "    X_answers.append(X_answer)\n",
        "  X_val = np.array(X_val)\n",
        "  X_answers = np.array(X_answers)\n",
        "  model.load_weights(os.path.join(root_path,f'{fold}-rain.h5'))\n",
        "\n",
        "  val_pred = model.predict(X_val)\n",
        "  test_pred = model.predict(X_test)\n",
        "\n",
        "  test_pred = test_pred.reshape(-1,14400)\n",
        "  final_X_val = val_pred.reshape(-1,14400)\n",
        "  total_val.append(final_X_val)\n",
        "  total_answer.append(X_answers)\n",
        "  test_preds.append(test_pred)\n",
        "  \n",
        "  del val_pred, X_val, X_answers, final_X_val\n",
        "  gc.collect()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "val: 100%|██████████| 12547/12547 [00:04<00:00, 2874.22it/s]\n",
            "val: 100%|██████████| 12547/12547 [00:04<00:00, 3012.70it/s]\n",
            "val: 100%|██████████| 12547/12547 [00:04<00:00, 2854.53it/s]\n",
            "val: 100%|██████████| 12547/12547 [00:31<00:00, 396.85it/s]\n",
            "val: 100%|██████████| 12547/12547 [00:30<00:00, 408.42it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXdfteSMyWCj",
        "outputId": "ad7987d4-8cc5-4edf-be23-9a1b76681ed8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "source": [
        "final_preds = (test_preds[0]+test_preds[1]+test_preds[2]+test_preds[3]+test_preds[4])/5\n",
        "sub = pd.read_csv(\"sample_submission.csv\")\n",
        "sub.iloc[:,1:] = final_preds.astype(int)\n",
        "sub.to_csv(\"submission.csv\", index=False)\n",
        "from google.colab import files\n",
        "files.download('submission.csv')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_7a84bf5b-32d8-45ec-b77b-ebaeaed1aea1\", \"submission.csv\", 81748241)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}